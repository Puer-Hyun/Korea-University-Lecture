# 2023-06-01-(목)-210204
## 목표
* 모든 코드는 from-scratch로 돌려보고, Recbole로도 실험을 해봐야겠다.
## NBCF
1. `knn_basic = KNNBasic(k=40, min_k=10)`으로 진행하니 학습시간만 한참 걸렸음. 
   * 위 코드는 3.8.5 recsys 가상환경에서 돌렸음.

## Recbole 연결
###  문제점
1. distutils라는 라이브러리가 3.8.5 에서는 동작하지 않는 것 같은데, 조현석 멤버는 돌렸다고 해서 3.8.16 버전을 설치하고 새로운 가상환경을 설치하려고 함.
2. recbole이 돌아가는 것 같긴 한데, wandb 설정, tensorboard 설정 등 설정할 수 있는 게 너무 많은 것 같다. 
3. 우선은 train_df 를 1%만 사용해서 데이터를 확 축소시켜서 전체 사이클을 돌려봐야겠다. 현재는 5백만개니까 짧은 실험이 감당이 되지 않는다.
4. 1%만 사용해서 돌리는 것은 성공했는데, run.py는 성공했으나 run_hyper.py는 아직 작동시키는 법을 모르겠다. 
   1. Hyperopt / numpy 버전 문제인 줄 알았는데 그건 아닌 것 같다.
   2. 모델마다 Config file을 어떻게 다뤄야하는 지 익혀야 할 것 같은데?

---
When I try to run fmin and define rstate as np.random.RandomState(SEED), I got the error

'numpy.random.mtrand.RandomState' object has no attribute 'integers'

My fmin call looks like this:
fmin(f_lgbm, lgbm_param, algo=tpe.suggest, max_evals=MAX_EVAL, trials=trials, rstate=np.random.RandomState(SEED))

I am running the latest hyperopt on conda python 3.8.6 on win11.

즉, Hyperopt를 관리하는 과정에서 numpy에서는 numpy.random.mtrand.RandomState라는 것이 없어졌다. 

<span style="color:red">

np.random.RandomState was deprecated, so Hyperopt now uses np.random.Generator. Replace the fmin call with:

fmin(f_lgbm, lgbm_param, algo=tpe.suggest, max_evals=MAX_EVAL, trials=trials, rstate=np.random.default_rng(SEED))

</span>

---


# 2023-06-02-(금)-102543
# 목표
- [x] ~~나가기 전까지 Hyper 실험할 수 있는 환경까지 만들어보기?~~
  * ~~그냥 Wandb Sweep으로 해결했음.~~ 
  
- [ ] 이제 다음 목표는 Valid Set 구축이다. 고정된 hyperparam에 대해서 단일모델을 여러 train, valid에 돌려 보았을 때, 가장 Robust한 것은 무엇인가?
- [ ] Valid Set을 따로 구축할 수도 있고, CV 전략을 recbole에서 구현해뒀을 것 같은데 체크해보자.
- [ ] Wandb에는 현재 best valid score만 뜨고 있다. epoch마다 valid score가 어떻게 변하는지도 기록할 수 있게 설정을 바꾸어보자.

## 실험 결과
* ItemKNN은 다음과 같다. (0.0054)
![](images/2023-06-03-10-09-35.png) 
* BPR 을 돌려보니까, 0.016이 최대이다. (1%에서)
![](images/2023-06-03-10-08-57.png)


### NeuMF (~0.03)
은 0.03 정도였다. (1%에서) 그리고 편차가 BPR보다 작았다. ![](images/2023-06-03-10-06-38.png)


### ConvNCF (0.025~0.027)
는 0.025~0.027인 것 같은데, 학습 시간이 아주 오래 걸렸다. 또한 GPU를 많이 잡아먹는 것 같아서, 쉽게 시도할 영역이 아닌 것 같기도 하다. ![](images/2023-06-03-10-27-12.png)
![](images/2023-06-03-11-02-52.png)
* Failed까지 뜬 걸 보면 용량을 많이 잡아먹는 것 같다. 따라서 보류.


### DMF (~0.03)
는 기본 모델로 돌렸을때 0.03까지 나왔음. 파라미터별로 변동성이 큰지 안큰지는 확인 안해봤음.


### FISM (~0.034)
은 0.034 정도까지 나왔는데, 1%만 사용했음에도 이정도의 가능성이 보였음. 


### NAIS (0.0022)
는 0.0022인데, ![](images/2023-06-03-11-35-55.png) 

이런 느낌인 걸로 봐서는 따로 학습하는 것이 아닌 것 같다.


### NGCF는 다음과 같은 느낌이다. train_loss 자체가 작은데 그 이유가 뭐지? 개수를 작게 잡아서 그럴지도 모른다. ![](images/2023-06-03-13-02-18.png)
* SpectralCF 는 학습속도도 빠르고 점수도 0.0283? ![](images/2023-06-03-13-10-28.png)
  
### GCMC (0.0298?)
* GCMC는 작은 데이터셋에 대해서는 과적합이 심한 것일까? 0.03을 넘지 못했고, 학습속도가 꽤 오래 걸린다. 이 말은 데이터셋이 100배 늘어나면 아주 오래 걸릴 것이란 뜻이다. ![](images/2023-06-03-13-18-14.png) 그런데 valid는 0.298정도인데 테스트가 0.0336? 정도면 괜찮은데?
### LightGCN (0.0191, 0.0212)
* 파라미터 수 1717952
* ![](images/2023-06-03-13-37-15.png)

### DGCF 
* 파라미터수 1717952
* ![](images/2023-06-03-13-41-19.png) 

### LGCN 모델과 DGCF 모델의 차이, 그리고 장단점
DGCF와 LightGCN은 둘 다 그래프 컨볼루션 네트워크를 기반으로 하는 모델입니다. 그러나 그들의 목표와 방법론에는 몇 가지 차이점이 있습니다.

**DGCF (Disentangled Graph Collaborative Filtering)**

DGCF는 사용자-아이템 상호작용 그래프에서 이질적인 관계를 분리하여 개별적으로 학습하고, 이러한 관계를 융합하여 최종 추천을 생성하는 방법을 제안합니다. DGCF는 사용자의 개인적인 편향과 사용자 간의 소셜 영향력을 분리하여 더 정확한 추천을 생성하려는 노력을 합니다.

**장점**: 
- DGCF는 그래프 구조를 사용하여 복잡한 사용자-아이템 상호작용을 모델링합니다.
- 이질적인 관계를 분리하여 학습하므로 각 관계의 별도의 영향력을 파악할 수 있습니다.

**단점**:
- 모델의 복잡성과 계산량이 늘어나므로 학습 시간이 길어질 수 있습니다.
- 모델의 효과는 주로 데이터가 충분히 크고 복잡할 때 나타납니다.

**LightGCN (Light Graph Convolutional Network)**

LightGCN은 그래프 컨볼루션 네트워크 (GCN)의 변형으로, 복잡한 레이어 정규화와 비선형 활성화 함수를 제거하여 모델의 복잡성을 줄이고 성능을 향상시키려고 합니다.

**장점**: 
- 모델이 간단하고 직관적이므로 이해하기 쉽고 구현하기 쉽습니다.
- 불필요한 요소를 제거함으로써 성능이 향상되며, 이는 여러 벤치마크 데이터 세트에서 입증되었습니다.

**단점**:
- 비선형 활성화 함수와 레이어 정규화를 제거하므로, 일부 복잡한 사용자-아이템 상호작용을 제대로 모델링하지 못할 수 있습니다.
- 그래프 구조의 정보만을 사용하여 추천을 생성하므로, 추가적인 사용자나 아이템의 특성을 고려하지 않습니다. 

두 모델 모두 그래프 정보를 이용하여 사용자와 아이템 사이의 복잡한 상호작용을 모델링하려고 시도하지만, 그들의 접

근 방식과 중점은 다릅니다. 선택할 모델은 당신의 문제 정의, 사용 가능한 데이터, 그리고 계산 자원 등에 따라 달라질 수 있습니다.

### LINE 모델 (성능이 좋지는 않음)
* 파라미터수 3435904
* 근데 train_loss가 음수가 나오는데 그 이유가 있는가? LINE 모델은 무엇인가?
* ![](images/2023-06-03-13-47-07.png) 


### MultiVAE (best valid : OrderedDict([('recall@10', 0.0301)]) test result: OrderedDict([('recall@10', 0.033)]))
* 파라미터수 6492637 * ![](images/2023-06-03-13-50-36.png)
* epoch 10만 돌리고 있는데, 금방 과적합이 되어버리는 경향이 있는 것 같기도?

RecBole에서 제공하는 General Recommendation 모델 중 대규모 데이터셋에 대해 잘 작동하는 모델은 아래와 같습니다:

1. **BPR (Bayesian Personalized Ranking):** 이 모델은 명시적인 평점 대신 사용자의 선호도 순위를 학습합니다. 이러한 접근 방식은 대규모 데이터셋에 잘 확장되며, 종종 implicit feedback 데이터셋에서 잘 작동합니다.

2. **NeuMF (Neural Matrix Factorization):** NeuMF는 기존의 Matrix Factorization 방식에 딥러닝 요소를 추가한 모델입니다. 이 모델은 대용량 데이터셋에 잘 확장될 수 있습니다.

3. **LightGCN:** LightGCN은 복잡한 변환을 최소화하여 더 간단하고 효과적인 GNN을 제안합니다. 이 간단한 설계 덕분에 LightGCN은 대규모 데이터셋에서 효과적으로 작동합니다.

4. **EASE (Embarrassingly Shallow AutoEncoders for Sparse Data):** 이 모델은 매우 효율적인 메모리 사용량과 높은 처리 속도를 제공하므로 대용량 데이터셋에 잘 확장될 수 있습니다.

다른 모델들도 대규모 데이터셋에서 효과적일 수 있지만, 특히 복잡한 모델 (예: DGCF, RecVAE 등)의 경우, 모델 복잡도나 학습 시간이 크게 증가할 수 있으므로 주의가 필요합니다.

그리고 일반적으로, 모델이 작은 데이터셋에서 잘 작동하지 않는다면, 같은 모델이 큰 데이터셋에서 잘 작동할 가능성은 적습니다. 그러나, 항상 그런 것은 아닙니다. 데이터 분포의 변화, 데이터 품질, 데이터에 내재된 패턴 등 다양한 요인이 모델의 성능에 영향을 미치기 때문에, 경우에 따라서는 1% 데이터에서 성능이 나쁘더라도 전체 데이터에서는 성능이 좋아질 수 있습니다. 

그러므로 최적의 모델을 선택하는 가장 좋은 방법은 여러 모델을 테스트하고 검증하는 것입니다. 이를 위해 교차 검증, 그리드 검색, 랜덤 검색 등의 기법을 사용하여 모델 성능을 향상시킬 수 있습니다.


### MultiDAE (test 0.0329)
* 파라미터수 6454173 
* ![](images/2023-06-03-13-54-36.png)
* 0.0329인데, 할만하지 않을까?
* 근데 이것도 조금 빠르게 과적합되는 느낌이 있네


### MacridVAE
* 파라미터수 3603344
* MultiVAE의 변형이라고 하는 것 같은데, 자세한 정보를 알 수가 없네. 파라미터수가 절반으로 감소한 것 같다. 일단은 맥크리드VAE는 이미지와 텍스트를 모두 처리할 수 있게 만든 모델이라고 Bard가 이야기했는데, 그 정보를 믿을 수 있는지는 몰?루?
* ![](images/2023-06-03-14-08-56.png) 


### CDAE
Collaborative Denoising AutoEncoder(CDAE)는 암묵적 피드백(implicit feedback)을 기반으로 한 추천 시스템을 위한 모델입니다. 2016년에 제안된 이 모델은 원래 사용자-아이템 상호작용 행렬의 빈 공간을 채우기 위해 개발되었습니다.

CDAE의 핵심 아이디어는 denoising autoencoder의 원리를 이용하여, 입력으로 들어온 사용자-아이템 상호작용을 재구성하는 것입니다. 그러나 입력의 일부가 무작위로 제거(즉, noise가 추가)된 상태에서 이 재구성이 수행되므로, 모델은 노이즈가 없는 원래의 입력을 복원하는 방법을 학습하게 됩니다. 이러한 과정을 통해, 모델은 사용자의 아이템에 대한 선호도를 보다 잘 모델링하게 됩니다.

CDAE의 장점:

암묵적 피드백 처리: CDAE는 암묵적 피드백(예: 클릭, 조회 등)을 잘 처리합니다. 이러한 데이터는 사용자의 긍정적인 피드백을 나타내지만, 사용자가 특정 아이템에 대해 의견을 내지 않은 경우의 의미에 대해 모호합니다. CDAE는 이러한 문제를 처리하는 데 효과적입니다.

고차원 및 희소 데이터 처리: CDAE는 고차원 및 희소한 사용자-아이템 상호작용 데이터를 처리하는 데 유용합니다.

CDAE의 단점:

새로운 아이템에 대한 처리: CDAE는 새로운 아이템(즉, 모델이 학습 과정에서 본 적 없는 아이템)에 대해 추천을 생성하는 데 어려움이 있습니다. 이는 모든 항목이 모델 학습 과정에 포함되어야 하기 때문입니다.

계산 비용: 큰 데이터셋에서 CDAE를 학습하는 것은 계산적으로 많은 비용이 들 수 있습니다. 이는 사용자와 아이템 간의 모든 가능한 상호작용을 모델링하려는 모델의 특성 때문입니다.

모델의 선택은 항상 당신의 특정 문제와 데이터에 의존하기 때문에, CDAE가 특정 문제에 가장 적합한 모델인지 확인하려면 직접 실험을 수행해야 합니다.

Collaborative Denoising AutoEncoder(CDAE)를 사용하는 주된 목적은 추천 시스템에서 사용자-아이템 상호작용에 기반한 고도의 개인화된 추천을 생성하는 것입니다. CDAE는 사용자와 아이템 간의 복잡한 상호작용을 학습하고 모델링하여, 사용자의 선호도를 더 잘 이해하고, 그에 따라 사용자가 관심을 가질 가능성이 높은 아이템을 추천합니다.

CDAE는 특히 암묵적 피드백 데이터(예: 사용자의 클릭, 조회 등)를 처리하는데 효과적입니다. 이러한 데이터는 사용자가 아이템을 얼마나 좋아하는지에 대한 강력한 신호를 제공하지만, 사용자가 아이템에 대해 의견을 내지 않은 경우의 의미는 불분명합니다. CDAE는 이러한 암묵적 피드백의 불확실성을 모델링하는데 도움을 줍니다.

더 나아가, CDAE는 대규모, 고차원, 희소한 사용자-아이템 상호작용 데이터를 처리하는데 유용합니다. 이는 실제 세계의 많은 추천 시스템 시나리오에서 공통적으로 나타나는 특성입니다. 이러한 이유로, CDAE는 사용자에게 맞춤화된 아이템 추천을 제공하는 다양한 추천 시스템에서 사용됩니다.

희소 데이터를 처리하기 좋다고 하는데 결과는 ![](images/2023-06-03-14-13-50.png) 

* 학습 속도는 빠르긴 하다.
### ENMF 
ENMF(Explainable Neural Matrix Factorization)는 추천 시스템에서 사용하는 알고리즘 중 하나로, 이 모델의 핵심 목표는 기존의 Matrix Factorization(MF) 기법을 확장하여 더욱 풍부한 사용자와 아이템의 상호작용 패턴을 학습하는 것입니다.

ENMF는 각 사용자와 아이템에 대한 잠재 요인(latent factors)을 학습하고, 이를 사용하여 사용자-아이템 행렬의 누락된 항목을 예측합니다. 그러나 기본 MF와 달리, ENMF는 뉴럴 네트워크를 사용하여 잠재 요인을 모델링하고 예측력을 향상시킵니다. 뉴럴 네트워크는 비선형 패턴을 학습할 수 있기 때문에, ENMF는 사용자와 아이템 간의 복잡한 상호작용을 더 잘 캡처할 수 있습니다.

ENMF의 장점:
1. 뉴럴 네트워크를 사용하므로, 사용자와 아이템 간의 복잡한 상호작용을 더 잘 학습할 수 있습니다.
2. 사용자와 아이템의 특성을 잘 포착하여, 더 정확한 예측을 제공할 수 있습니다.
3. 추천의 해석 가능성을 높이는데 유용합니다. MF 모델은 보통 "블랙박스"로 간주되지만, ENMF는 뉴럴 네트워크의 중간 계층을 통해 추천의 원인을 설명하는 데 도움이 될 수 있습니다.

ENMF의 단점:
1. 뉴럴 네트워크를 학습하는 것은 종종 복잡하고 시간이 많이 걸릴 수 있습니다. 따라서, ENMF는 계산적으로 더욱 요구사항이 높습니다.
2. ENMF는 하이퍼파라미터가 많이 필요하며, 이를 최적화하는 것이 어려울 수 있습니다. 이로 인해 모델의 성능이 상당히 민감하게 반응할 수 있습니다.
3. MF와 마찬가지로, ENMF는 "cold-start" 문제에 대해 취약합니다. 즉, 새로운 사용자나 아이템에 대한 정보가 부족할 때 예측력이 떨어집니다.

참고로, 제가 제공한 이 내용은 대략적인 개요이며, 실제로 ENMF를 적용할 때는 모델의 구체

적인 세부 사항과 사용자와 아이템의 특성, 그리고 목표 작업에 따라 성능과 적합성이 달라질 수 있습니다.
![](images/2023-06-03-15-01-10.png)
* train_loss가 무한대로 발산하고 있는데 이게 맞나?
* 일단 epoch11까지는 무난하게 0.002부터 0.02까지 올라가길래 epoch 100으로 실험해봤구만.... 아깝다.


### NNCF 모델 

### RecVAE
![](images/2023-06-04-14-35-40.png)
* 학습속도는 빠르지만, 성능이 그렇게 좋지는 않은 것 같다
  

### EASE 모델 
* ![](images/2023-06-04-14-43-21.png)
* 위의 내용을 보면 학습이 이루어지는 게 아닌 것 같아서, 나중에 대형 모델에 다시 넣어봐야할듯


### SLIMElastic
![](images/2023-06-05-02-24-23.png)
SLIMElastic은 학습속도가 아주 빠른 것 같았다. 그런데 0.0073, 0.0091이라 성능은 몰루?

### SGL
![](images/2023-06-05-02-27-31.png)


### ADMMSLIM 
![](images/2023-06-05-02-31-44.png)


### NCEPLRec
![](images/2023-06-05-02-34-42.png)

train_loss, valid_score 모두 변함이 없다. 중간에 멈춤

### SimpleX
학습속도는 빠른 것 같은데 성능은 영
![](images/2023-06-05-02-37-55.png)

심플렉스법은 선형계획 문제를 푸는 데 사용되는 알고리즘입니다. 선형계획 문제는 제한된 자원을 사용하여 최대 또는 최소의 목적함수 값을 찾는 문제입니다. 심플렉스법은 가능한 해 중에서 최적의 해를 찾는 데 사용됩니다.

심플렉스법은 다음과 같은 단계로 이루어집니다.

제약조건을 등식으로 바꿉니다.
목적함수를 기준으로 변수를 선택합니다.
선택한 변수를 0으로 만들기 위해 제약조건을 조정합니다.
3번의 과정을 반복하여 최적의 해를 찾습니다.
심플렉스법은 선형계획 문제를 푸는 데 가장 효율적인 알고리즘 중 하나입니다. 그러나, 제약조건이 많거나 복잡한 경우에는 심플렉스법을 사용하기 어려울 수 있습니다.

다음은 심플렉스법을 사용하여 선형계획 문제를 푸는 예입니다.

목적함수: Z = 2x + 3y
제약조건:

x + y <= 10
x - y >= 0
x, y >= 0
심플렉스법을 사용하여 이 문제를 푸는 방법은 다음과 같습니다.

제약조건을 등식으로 바꿉니다.
x + y = 10
x - y = 0
x = 0
y = 0

목적함수를 기준으로 변수를 선택합니다.
목적함수에서 x의 계수는 2이고 y의 계수는 3이므로 x를 선택합니다.

선택한 변수를 0으로 만들기 위해 제약조건을 조정합니다.
x + y = 10에서 x를 0으로 만들기 위해 y = 10을 대입합니다.

x - y = 0에서 x를 0으로 만들기 위해 y = 0을 대입합니다.

3번의 과정을 반복하여 최적의 해를 찾습니다.
최적의 해는 x = 0, y = 10입니다. 따라서, 목적함수의 최적의 값은 Z = 20입니다.

만약 "Simplex"가 선형 프로그래밍 문제를 해결하는 알고리즘인 Simplex method를 의미하는 것이라면, 그에 대해 설명해드릴 수 있습니다. Simplex method는 선형 프로그래밍 문제를 해결하기 위한 방법으로, 1947년에 George Dantzig에 의해 개발되었습니다. 이 알고리즘은 기본적으로 해집합을 탐색하며 목표 함수를 최적화하는 데 사용됩니다.


### NCL 모델 (시도해볼만한 가치가 있음.)


그러한 모델에 대한 설명이 있네요. 주어진 논문에 따르면, Neighborhood-enriched Contrastive Learning (NCL)은 최근에 제안된 그래프 협업 필터링 방법을 향상시키는데 사용되는 새로운 대조적 학습 방법입니다.

이 방법은 사용자-아이템 상호작용 그래프를 모델링하여 사용자의 아이템에 대한 선호도를 캡처합니다. 그러나 데이터 희소성 문제로 인해 이러한 방법의 효과가 제한됩니다. 이 문제를 해결하기 위해 NCL은 대조적 학습을 도입하여 그래프 협업 필터링의 성능을 향상시키려고 합니다.

NCL은 이웃 강화 대조 학습으로, 명시적으로 잠재 이웃을 대조 쌍에 포함시킵니다. 구조적 이웃은 상호 작용 그래프에서 사용자(또는 아이템)의 이웃을 도입하고, 이들을 긍정적인 대조 쌍으로 간주하는 새로운 구조 대조 목표를 개발합니다. 의미적 공간에서의 잠재적 이웃 관계를 파헤치기 위해, 유사한 표현을 가진 사용자들이 의미적 이웃 내에 있다고 가정하고, 이들 의미적 이웃을 프로토타입 대조 목표에 포함시킵니다.

NCL은 EM 알고리즘으로 최적화되고 그래프 협업 필터링 방법에 적용될 수 있습니다. 대중적인 데이터 세트에서의 광범위한 실험은 NCL의 효과를 입증하며, Yelp와 Amazon-book 데이터셋에서는 기존 그래프 협업 필터링 모델에 비해 각각 26%와 17%의 성능 향상을 보여줍니다.

<span style="color:red">EM 알고리즘(Expectation-Maximization algorithm)</span>은 관측되지 않은 잠재 변수를 포함하는 확률 모델에서 최대 가능도 추정치를 찾는데 사용되는 통계적 알고리즘입니다.

EM 알고리즘은 두 단계가 반복되는 반복적인 절차를 포함합니다:

Expectation(E) 단계: 현재 추정치를 고정하고 잠재 변수에 대한 기대치를 계산합니다.

Maximization(M) 단계: 이 기대치를 사용하여 가능도를 최대화하는 모델 파라미터를 추정합니다.

EM 알고리즘은 대표적으로 혼합 모델(mixture model, 예를 들어 Gaussian Mixture Model)을 추정하는데 사용되며, 다른 많은 통계적, 기계 학습 모델에서도 사용됩니다. EM 알고리즘의 장점 중 하나는 각 단계가 종종 계산적으로 간단한 형태를 갖는다는 것입니다. 또한 EM 알고리즘은 주어진 데이터에서 잠재 변수의 분포를 추정하는데 유용합니다.

## Sequential Recommendation
### FPMC  
![](images/2023-06-05-02-53-54.png)
### GRU4Rec
GRU4Rec을 돌릴때는 이런 config를 기본으로 돌려야할 것 같아.
```python

data_path: ./data
dataset: movie
field_separator: "	"
seq_separator: " "
USER_ID_FIELD: user
ITEM_ID_FIELD: item
LABEL_FIELD: label
TIME_FIELD: time
show_progress: false
use_gpu: true
use_tensorboard: false  # tensorboard 사용하지 않음
log_wandb: True
loss_type: BPR

load_col:
    inter: [user, item, time]
    user: [user]
    item: [item, genre, director, title, writer, year]

user_inter_num_interval: "[0,inf)"
item_inter_num_interval: "[0,inf)"

epochs: 100
metrics: ["Recall"]
topk: [10]
valid_metric: Recall@10

eval_args:
  split: {'RS':[0.8,0.15,0.05]}
  group_by: user
  order: TO
  mode: full

k: 50
```
 
![](images/2023-06-05-03-07-09.png)

일단 성능은 이정도 되는 것 같네.

### NARM
![](images/2023-06-05-03-09-08.png)

### STAMP
![](images/2023-06-05-03-09-56.png) 

### Caser
일단 학습속도가 **어마어마하게 오래 걸리는 것 같다?** 성능은 잘 올라갈수도 있을 것 같은데. 이건 자고 일어나서 확인해봐야하나?
![](images/2023-06-05-03-53-44.png)

### NextItNet 
학습속도 빠름 
![](images/2023-06-05-03-59-48.png)

### SASRec
<span style="color:red">빠르고 성능 나쁘지않음 </span>

### SRGNN
속도도 1epoch당 6초정도 걸리고, 성능도 0.011 수준이라 시도 안해보는 게 나을지도?

### SRGNN 
![](images/2023-06-05-04-08-14.png)


### <span style="color:red">**RepeatNET**</span> 
![](images/2023-06-05-14-12-41.png)

전체 데이터 셋을 다 썼을 때 1회 돌릴 때 100분씩 걸린다는 단점이 있는데, 0.14까지 나오는 걸 보면 시도해볼만한 가치는 있는 것 같다.

![](images/2023-06-07-02-17-45.png)!

0.1571까지는 확인

# 2023-06-08-(목)-181023
## Multi-VAE를 돌릴 때 고려해볼만한 사항
* EDA 과정을 통해서, 최종적으로 예측한 영화의 개봉일이, 해당 유저가 마지막으로 본 영화의 x년째 이내의 데이터인지 확인할 것.
  * 고전 영화를 좋아할지, 최신 영화를 좋아할 지 등등

- [ ] 우선 다른 것들을 공부할 떄 Multi-VAE, Multi-DAE 를 계속 실험해볼 수 있는 환경을 만들어두자.
- [ ] 다른 이론들을 열심히 공부하면서 하나씩 구현해보자. 
- [ ] Recsys 기초, Recsys 강의에 나온 것들을 하나씩 구현할 수 있도록 하자.
- [ ] 그 어떤 과정도 EDA가 제대로 되면 성능을 올릴 수 있다. EDA가 1순위이다.
  - [ ] Data Centric하게 목적을 달성할 수 있도록, 